{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedded Bidirectional LSTM Siamese Network Export\n",
    "\n",
    "This notebook shows how to export a trained sentence similarity/sentence embedding model using word embedding and bidirectional LSTM on a siamese network. In general though it is easier to export after the training but in some cases people might want to separate the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import kotoba as kt\n",
    "import narau as nr\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data related constants\n",
    "\n",
    "*   ```MODEL_DIR```: Directory of the model to export\n",
    "*   ```EMBEDDING_FILE```: Path to the Glove embedding file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'word_bilstm_glove_siamese\\\\model\\\\1536902903'\n",
    "EMBEDDING_FILE = os.path.expanduser('~/Documents/data/glove.6B/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model related constants\n",
    "\n",
    "*   ```EMBEDDING_WEIGHTS```: Initial weights of the embedding layer\n",
    "*   ```EMBEDDING_SIZE```: Number of tokens in the embedding\n",
    "*   ```EMBEDDING_DIMENSION```: Number of dimensions in the dense representation\n",
    "*   ```EMBEDDING_SPECIAL_TOKENS```: Number of special tokens\n",
    "*   ```EMBEDDING_WITH_PAD```: If embedding includes a padding\n",
    "*   ```EMBEDDING_TRAINABLE```: If embedding is trainable\n",
    "*   ```EMBEDDING_UNITS```: List of units in the embedding transform function\n",
    "*   ```LSTM_UNITS```: List of the LSTM units\n",
    "*   ```LSTM_DROPOUT```: LSTM output dropout probability\n",
    "*   ```PROJECTION_UNITS```: List of units of the projection. Last item determines embedding dimensions\n",
    "*   ```LOSS_MARGIN```: Target distance between different sentences\n",
    "*   ```LEARNING_RATE```: Rate of gradient application\n",
    "\n",
    "Note: There is no guarantee if it would work if the parameters are different so they are kept the same. However it is recommended to just inherit the model and override its constructor arguments so that there is no need to redefine these constant in two separate scripts/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_WEIGHTS = nr.embedding.load_glove_weights(EMBEDDING_FILE)\n",
    "EMBEDDING_SIZE = EMBEDDING_WEIGHTS.shape[0]\n",
    "EMBEDDING_DIMENSION = EMBEDDING_WEIGHTS.shape[1]\n",
    "EMBEDDING_SPECIAL_TOKENS = 2\n",
    "EMBEDDING_WITH_PAD = True\n",
    "EMBEDDING_TRAINABLE = False\n",
    "\n",
    "EMBEDDING_UNITS = [128]\n",
    "\n",
    "LSTM_UNITS = [128]\n",
    "LSTM_DROPOUT = 0.5\n",
    "\n",
    "PROJECTION_UNITS = [1024]\n",
    "\n",
    "LOSS_MARGIN = 1.0\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a preprocessing pipeline\n",
    "A pipeline is created for the preprocessing of the model. This is because some of the preprocessing is done outside tensorflow. A pipeline that directly converts the text to a serialized TFRecord is created using kotoba. The logic is similar to the preprocessing done during the training. This time however, there is no label to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(kt.Preprocessor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._pipeline = kt.Pipeline([\n",
    "            kt.LowerCase(),\n",
    "            kt.tokenizer.NLTKTokenizer(),\n",
    "            kt.embedding.EmbedTokenToID(\n",
    "                kt.embedding.Embedding.from_glove_file(EMBEDDING_FILE, ['<PAD>', '<UNK>'], 1)\n",
    "            ),\n",
    "        ])\n",
    "        \n",
    "    def transform(self, x, as_iterable=False):\n",
    "        x_pipelined = self._pipeline.transform(x, True)\n",
    "        example = nr.example.SequenceExample(\n",
    "            nr.example.FeatureLists({\n",
    "                'x': nr.example.Int64FeatureList(x_pipelined)\n",
    "            })\n",
    "        )\n",
    "        return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the serving API\n",
    "To serve a model, the signature for using the model must be defined. Here a function that returns a ```ServingInputReceiver``` must be defined. In that function, the processing to load the data to the model must also be defined. The loading processing is similar to the training process. The only difference is that there are no labels this time.\n",
    "\n",
    "References:\n",
    "*   ```Exporting Models```: https://www.tensorflow.org/guide/saved_model#using_savedmodel_with_estimators\n",
    "*   ```ServingInputReceiver```: https://www.tensorflow.org/api_docs/python/tf/estimator/export/ServingInputReceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_key = 'x'\n",
    "\n",
    "_feature_def = {\n",
    "    _key: tf.VarLenFeature(tf.int64),\n",
    "}\n",
    "\n",
    "def parse_example(example):\n",
    "    context, features = tf.parse_single_sequence_example(example, sequence_features=_feature_def)\n",
    "    return features\n",
    "\n",
    "def preprocess_text(x):\n",
    "    x = tf.sparse_reset_shape(x)\n",
    "    x = tf.sparse_tensor_to_dense(x)\n",
    "    return x, tf.size(x)\n",
    "\n",
    "def preprocess_elements(features):\n",
    "    x, l = preprocess_text(features[_key])\n",
    "    return (x, l)\n",
    "\n",
    "def input_fn(serialized_example):\n",
    "    parsed_example = parse_example(serialized_example)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(parsed_example)\n",
    "    ds = ds.map(preprocess_elements, num_parallel_calls=8)\n",
    "    ds = ds.padded_batch(parsed_example[_key].dense_shape[0], ([None], []))\n",
    "    it = ds.make_initializable_iterator()\n",
    "    with tf.control_dependencies([it.initializer]):\n",
    "        data = it.get_next()\n",
    "    return data\n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    serialized_example = tf.placeholder(tf.string, [])\n",
    "    receiver_tensors = {'input': serialized_example}\n",
    "    features = input_fn(serialized_example)\n",
    "    features_dict = {\n",
    "        'x': features[0],\n",
    "        'len': features[1],\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features_dict, receiver_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the session and run configurations\n",
    "The model should not need these settings since the model will not be executed. However the same config with the training is used here just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_config = tf.ConfigProto()\n",
    "session_config.allow_soft_placement = True\n",
    "session_config.gpu_options.allow_growth = True\n",
    "\n",
    "config = tf.estimator.RunConfig(tf_random_seed=None,\n",
    "                                save_summary_steps=50,\n",
    "                                save_checkpoints_steps=400,\n",
    "                                keep_checkpoint_max=None,\n",
    "                                session_config=session_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "It is recommended that the model is subclassed so that the constants doesn't have to be defined everytime. However for this code the settings in the training is directly copied to the export to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = nr.estimators.SiameseBiLSTMEmbedding(EMBEDDING_SIZE, \n",
    "                                           EMBEDDING_DIMENSION, \n",
    "                                           EMBEDDING_SPECIAL_TOKENS,\n",
    "                                           EMBEDDING_WITH_PAD, \n",
    "                                           EMBEDDING_WEIGHTS,\n",
    "                                           EMBEDDING_TRAINABLE, \n",
    "                                           EMBEDDING_UNITS,\n",
    "                                           LSTM_UNITS,\n",
    "                                           LSTM_DROPOUT,\n",
    "                                           PROJECTION_UNITS,\n",
    "                                           LOSS_MARGIN,\n",
    "                                           LEARNING_RATE,\n",
    "                                           MODEL_DIR,\n",
    "                                           config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the model\n",
    "Export the model by providing an output path and the function that return the ```ServingInputReceiver```. This will create a file that can be used to deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = clf.export_savedmodel('word_bilstm_glove_siamese\\\\savedmodel\\\\1536902903', serving_input_receiver_fn)\n",
    "export_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Preprocessor\n",
    "The preprocessor is exported after the model so that the name of the path for the preprocessor is similar to the path of the exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_path = export_path + b'_prep.pkl'\n",
    "with open(prep_path, 'wb') as file:\n",
    "    cloudpickle.dump(prep, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
